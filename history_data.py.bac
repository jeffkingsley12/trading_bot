import pandas as pd
import numpy as np
from typing import Optional, List
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_squared_error, r2_score
from ta.volatility import AverageTrueRange, BollingerBands
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor
from ta.momentum import RSIIndicator
from ta.trend import MACD, SMAIndicator
from logs import logger
from decimal import Decimal
from config import CONFIG
from utils import round_decimal, apply_total_signal, adjust_number
import joblib
import asyncio
import os


precision = CONFIG["precision"]
multipliers = CONFIG["best_params"]  # Changed from "multipliers" to "best_params"


async def train_and_save_ml_model(
    df: pd.DataFrame,
    model_path: str = "rf_model.joblib",
    scaler_path: str = "scaler.joblib",
):
    features = [
        "open",
        "high",
        "low",
        "close",
        "volume",
        "atr",
        "rsi",
        "SMA",
        "MACD",
        "MACD_Signal",
        "SMA_50",
        "SMA_200",
        "bbm",
        "bbh",
        "bbl",
        "bb_width",
    ]
    X = df[features]
    y = df["close"].shift(-1)

    X = X[:-1]
    y = y[:-1]

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    loop = asyncio.get_running_loop()
    with ProcessPoolExecutor() as pool:
        model = await loop.run_in_executor(pool, train_model, X_train_scaled, y_train)

    y_pred = model.predict(X_test_scaled)
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    logger.info(f"Model performance - MSE: {mse:.4f}, R2: {r2:.4f}")

    await asyncio.gather(
        loop.run_in_executor(None, joblib.dump, model, model_path),
        loop.run_in_executor(None, joblib.dump, scaler, scaler_path),
    )

    logger.info(f"Model saved to {model_path}")
    logger.info(f"Scaler saved to {scaler_path}")

    print(f"Model training complete. MSE: {mse:.4f}, R2: {r2:.4f}")

    return model, scaler, mse, r2


def train_model(X_train_scaled, y_train):

    tscv = TimeSeriesSplit(n_splits=n_splits)

    model = RandomForestRegressor(n_estimators=100, random_state=42)
    
    mse_scores = []
    r2_scores = []

    for train_index, test_index in tscv.split(X):
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y.iloc[train_index], y.iloc[test_index]
        
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        
        mse_scores.append(mean_squared_error(y_test, y_pred))
        r2_scores.append(r2_score(y_test, y_pred))

    logger.info(f"Mean MSE: {np.mean(mse_scores):.4f} (+/- {np.std(mse_scores) * 2:.4f})")
    logger.info(f"Mean R2: {np.mean(r2_scores):.4f} (+/- {np.std(r2_scores) * 2:.4f})")

    # Train final model on all data
    model.fit(X, y)
    return model


async def load_model_and_predict(
    df: pd.DataFrame,
    model_path: str = "rf_model.joblib",
    scaler_path: str = "scaler.joblib",
) -> pd.DataFrame:
    features = [
        "open",
        "high",
        "low",
        "close",
        "volume",
        "atr",
        "rsi",
        "SMA",
        "MACD",
        "MACD_Signal",
        "SMA_50",
        "SMA_200",
        "bbm",
        "bbh",
        "bbl",
        "bb_width",
    ]

    if not os.path.exists(model_path) or not os.path.exists(scaler_path):
        raise FileNotFoundError(
            "Model or scaler file not found. Please train the model first."
        )

    loop = asyncio.get_running_loop()
    with ThreadPoolExecutor() as pool:
        model, scaler = await asyncio.gather(
            loop.run_in_executor(pool, joblib.load, model_path),
            loop.run_in_executor(pool, joblib.load, scaler_path),
        )

    logger.info("Model and scaler loaded successfully")

    X_predict = await loop.run_in_executor(None, scaler.transform, df[features])
    raw_predictions = await loop.run_in_executor(None, model.predict, X_predict)

    raw_predictions = np.round(raw_predictions, CONFIG["precision"])

    # adjusted_predictions = await loop.run_in_executor(None, np.vectorize(adjust_number), raw_predictions)

    df["ML_Prediction"] = raw_predictions

    logger.info(f"Predictions completed and added to dataframe")

    return df


async def get_historical_data(
    client,
    symbol: str = CONFIG["symbol"],
    interval: str = CONFIG["interval"],
    limit: int = int(CONFIG["limit"]),  # Convert to int
) -> Optional[pd.DataFrame]:
    raw_data = await fetch_and_process_data(client, symbol, interval, limit)
    if raw_data is None:
        return None

    df = await calculate_indicators(raw_data)
    df = await calculate_signals(df)
    df = await apply_total_signal(df)
    df = await load_model_and_predict(df)  # Use the pre-trained model for predictions
    df = await calculate_trade_parameters(df)

    await log_signals(df, symbol)

    return await clean_dataframe(df)


async def fetch_and_process_data(
    client, symbol: str, interval: str, limit: int
) -> Optional[pd.DataFrame]:
    try:
        raw_data = client.klines(symbol, interval, limit=limit)
        if not raw_data:
            logger.warning(f"No raw data fetched for {symbol}")
            return None

        df = pd.DataFrame(
            raw_data,
            columns=[
                "open_time",
                "open",
                "high",
                "low",
                "close",
                "volume",
                "close_time",
                "qav",
                "num_trades",
                "taker_base_vol",
                "taker_quote_vol",
                "ignore",
            ],
        )
        df.index = pd.to_datetime(df["open_time"], unit="ms")
        df = df[["open", "high", "low", "close", "volume"]].astype(float)
        df.dropna(inplace=True)

        if df.empty:
            logger.warning(f"Processed DataFrame is empty for {symbol}")
            return None

        return df
    except Exception as e:
        logger.error(f"Error processing data for {symbol}: {e}")
        return None


async def calculate_indicators(df: pd.DataFrame) -> pd.DataFrame:
    atr_indicator = AverageTrueRange(
        high=df["high"], low=df["low"], close=df["close"], window=14
    )
    df["atr"] = atr_indicator.average_true_range()

    rsi_indicator = RSIIndicator(close=df["close"], window=14)
    df["rsi"] = rsi_indicator.rsi()

    sma_indicator = SMAIndicator(close=df["close"], window=20)
    df["SMA"] = sma_indicator.sma_indicator().round(precision)

    macd_indicator = MACD(
        close=df["close"], window_fast=12, window_slow=26, window_sign=9
    )
    df["MACD"] = macd_indicator.macd().round(precision)
    df["MACD_Signal"] = macd_indicator.macd_signal().round(precision)

    df["SMA_50"] = SMAIndicator(close=df["close"], window=50).sma_indicator()
    df["SMA_200"] = SMAIndicator(close=df["close"], window=200).sma_indicator()

    bb_indicator = BollingerBands(close=df["close"], window=14, window_dev=2)
    df["bbm"] = bb_indicator.bollinger_mavg().round(precision)
    df["bbh"] = bb_indicator.bollinger_hband().round(precision)
    df["bbl"] = bb_indicator.bollinger_lband().round(precision)
    df["bb_width"] = bb_indicator.bollinger_wband()

    return df


async def calculate_signals(df: pd.DataFrame) -> pd.DataFrame:
    df["MACD_Crossover"] = df["MACD"] > df["MACD_Signal"]
    df["UPTREND"] = df["SMA_50"] > df["SMA_200"]

    current_price = df["close"].iloc[-1]
    last_sma = df["SMA"].iloc[-1]

    df["current_l"] = current_price < last_sma
    df["current_h"] = current_price > last_sma

    return df


async def calculate_trade_parameters(df: pd.DataFrame) -> pd.DataFrame:
    current_price = Decimal(str(df["close"].iloc[-1]))
    atr = Decimal(str(df["atr"].iloc[-1]))
    last_rsi = Decimal(str(df["rsi"].iloc[-1]))
    current_change = Decimal(str(df["close"].pct_change().iloc[-1]))
    ml_prediction = Decimal(str(df["ML_Prediction"].iloc[-1]))

    risk_amount = round_decimal(
        Decimal(str(CONFIG["account_balance"]))
        * Decimal(str(CONFIG["risk_percentage"])),
        CONFIG["precision"],
    )
    buy_price = round_decimal(
        current_price * (Decimal("1") - Decimal(str(CONFIG["deviation_percentage"]))),
        CONFIG["precision"],
    )
    sell_price = round_decimal(
        current_price * (Decimal("1") + Decimal(str(CONFIG["deviation_percentage"]))),
        CONFIG["precision"],
    )
    profit = Decimal(str(CONFIG["profit_target"]))
    stop_loss_value = round_decimal(
        current_price - Decimal(str(CONFIG["trailing_stop_loss_offset"])),
        CONFIG["precision"],
    )
    quantity = max(
        int(risk_amount / buy_price),
        int(CONFIG["minimum_lot_size"]),  # Convert to int
    )

    buy_signals = df["BuySignal"].iloc[-1] == 1
    sell_signals = df["SellSignal"].iloc[-1] == 1

    buy_price = (
        ml_prediction if (buy_signals and ml_prediction < current_price) else buy_price
    )
    sell_price = (
        ml_prediction
        if (sell_signals and ml_prediction > current_price)
        else sell_price
    )

    df["Buy_Price"] = buy_price
    df["Sell_Price"] = sell_price
    df["Stop_Loss"] = stop_loss_value
    df["Risk_Amount"] = risk_amount
    df["Profit_Target"] = profit
    df["Quantity"] = quantity
    df["Price_Change"] = current_change

    df["long_entry"] = (
        (df["close"].pct_change() < -float(profit))
        | (df["close"] > (df["close"] + float(stop_loss_value)))
        | (df["ML_Prediction"] > df["close"])
    )
    df["short_entry"] = (
        df["current_h"]
        & ~df["MACD_Crossover"]
        & ~df["UPTREND"]
        & (df["ML_Prediction"] > df["close"])
        & sell_signals
    )

    df["exit_long"] = (
        (df["close"].pct_change() > float(profit))
        | (df["close"] < float(stop_loss_value))
        | (df["ML_Prediction"] < df["close"])
    )
    df["exit_short"] = (
        (df["close"].pct_change() < -float(profit))
        | (df["close"] > (df["close"] + float(stop_loss_value)))
        | (df["ML_Prediction"] > df["close"])
    )

    df["Buy"] = df["long_entry"] | df["exit_short"]
    df["Sell"] = df["short_entry"] | df["exit_long"]

    if "Buy" not in df.columns:
        df["Buy"] = False
        logger.info("Buy colum is not in Dataframe")
    if "Sell" not in df.columns:
        logger.info("Buy colum is not in Dataframe")
        df["Sell"] = False

    df["Buy"] = df["long_entry"] | df["exit_short"]
    df["Sell"] = df["short_entry"] | df["exit_long"]

    best_params = await optimize_parameters(df)
    logger.info(f"Optimal parameters: {best_params}")
    CONFIG.update(best_params)
    df = await apply_stop_loss_updates(df, best_params["atr_multiplier"])

    return df


async def log_signals(df: pd.DataFrame, symbol: str) -> None:
    if df["Buy"].iloc[-1] or df["Sell"].iloc[-1]:
        logger.info(
            "Sell and Buy signals for %s:\n%s",
            symbol,
            df[["close", "rsi", "bbm", "bbh", "bbl", "atr", "SMA", "ML_Prediction"]]
            .tail(1)
            .to_string(),
        )
    else:
        logger.info(
            "No buy or sell signals for %s:\n%s",
            symbol,
            df[["close", "rsi", "bbm", "bbh", "bbl", "atr", "SMA", "ML_Prediction"]]
            .tail(1)
            .to_string(),
        )


async def clean_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    columns_to_drop = [
        "SMA_50",
        "SMA_200",
        "MACD",
        "MACD_Signal",
        "bbm",
        "bbh",
        "bbl",
        "atr",
        "SMA",
        "volume",
        "close_time",
        "qav",
        "num_trades",
        "taker_base_vol",
        "taker_quote_vol",
        "ignore",
    ]
    df = df.drop(columns_to_drop, axis=1, errors="ignore")
    return df


async def update_stop_loss(row):
    if row["Buy"] and row["close"] > row["stop_loss"]:
        return row["close"] - float(str(CONFIG["trailing_stop_loss_offset"]))
    elif row["Sell"] and row["close"] < row["stop_loss"]:
        return row["close"] + float(str(CONFIG["trailing_stop_loss_offset"]))
    else:
        return row["stop_loss"]


async def update_stop_loss_with_atr(row, atr_multiplier):
    if row["Buy"]:
        return row["close"] - float(
            row["atr"] * float(atr_multiplier)
        )  # Convert to float
    elif row["Sell"]:
        return row["close"] + float(
            row["atr"] * float(atr_multiplier)
        )  # Convert to float
    else:
        return row["stop_loss"]


async def apply_stop_loss_updates(
    df: pd.DataFrame, atr_multiplier: Decimal
) -> pd.DataFrame:
    # Initialize stop_loss column if it doesn't exist
    if "stop_loss" not in df.columns:
        df["stop_loss"] = df["close"]  # Initialize with current close price

    # Update stop_loss based on trailing stop
    df["stop_loss"] = await asyncio.gather(
        *[update_stop_loss(row) for _, row in df.iterrows()]
    )

    # Update stop_loss based on ATR
    df["stop_loss"] = await asyncio.gather(
        *[update_stop_loss_with_atr(row, atr_multiplier) for _, row in df.iterrows()]
    )

    return df


async def backtest_strategy(data: pd.DataFrame, multiplier: Decimal) -> dict:
    data["stop_loss"] = data["close"] - (data["atr"].apply(float) * float(multiplier))
    data["signal"] = np.where(data["close"] > data["stop_loss"], 1, -1)
    data["daily_return"] = data["close"].pct_change() * data["signal"].shift(1)
    data["cumulative_return"] = (1 + data["daily_return"]).cumprod()

    profit_loss_ratio = data["daily_return"].mean() / data["daily_return"].std()
    win_loss_ratio = (
        data.loc[data["daily_return"] > 0, "daily_return"].count()
        / data.loc[data["daily_return"] < 0, "daily_return"].count()
    )
    max_drawdown = (
        data["cumulative_return"].cummax() - data["cumulative_return"]
    ).max()

    return {
        "profit_loss_ratio": profit_loss_ratio,
        "win_loss_ratio": win_loss_ratio,
        "max_drawdown": max_drawdown,
    }


async def calculate_atr_multiplier(
    data: pd.DataFrame, multipliers: List[Decimal]
) -> Decimal:
    performance_metrics = []

    for multiplier in multipliers:
        metrics = await backtest_strategy(data, multiplier)
        performance_metrics.append((multiplier, metrics))

    metrics_df = pd.DataFrame(performance_metrics, columns=["multiplier", "metrics"])
    metrics_df = pd.json_normalize(metrics_df["metrics"])
    metrics_df["multiplier"] = metrics_df["multiplier"]

    best_multiplier = metrics_df.loc[
        metrics_df["profit_loss_ratio"].idxmax(), "multiplier"
    ]
    return best_multiplier


async def optimize_parameters(df: pd.DataFrame) -> dict:
    risk_percentages = [Decimal("0.01"), Decimal("0.02"), Decimal("0.03")]
    profit_targets = [Decimal("0.02"), Decimal("0.03"), Decimal("0.04")]
    stop_loss_offsets = [Decimal("0.005"), Decimal("0.01"), Decimal("0.015")]
    atr_multipliers = [Decimal("1.5"), Decimal("2"), Decimal("2.5")]

    best_params = {}
    best_performance = float("-inf")

    for risk in risk_percentages:
        for profit in profit_targets:
            for stop_loss in stop_loss_offsets:
                for atr_mult in atr_multipliers:
                    CONFIG["risk_percentage"] = risk
                    CONFIG["profit_target"] = profit
                    CONFIG["trailing_stop_loss_offset"] = stop_loss

                    df_copy = df.copy()
                    df_copy = await apply_stop_loss_updates(df_copy, atr_mult)
                    metrics = await backtest_strategy(df_copy, atr_mult)

                    performance = metrics["profit_loss_ratio"]
                    if performance > best_performance:
                        best_performance = performance
                        best_params = {
                            "risk_percentage": risk,
                            "profit_target": profit,
                            "stop_loss_offset": stop_loss,
                            "atr_multiplier": atr_mult,
                        }

    return best_params
